{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = \"../log_files/BAT-clean_adv_distribution-Madry_loss/BAT-clean_adv_distribution-Madry_loss-Madry_loss--epochs_110-weight_decay_0.0005-lr_max_0.1-epsilon_0.06274509803921569-num_steps_10-step_size_0.00784313725490196-seed_0-/20220410131028_y63mvmvg\"\n",
    "\n",
    "all_data = [torch.load(os.path.join(dir_data, f\"dis_measure_{i}.pth\")) for i in range(1, 111)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_all_data = np.average([i['bn1.bn_list.0.running_mean'] for i in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "dir_data = \"../log_files/BAT-clean_adv_distribution-Madry_loss/BAT-clean_adv_distribution-Madry_loss-Madry_loss--epochs_110-weight_decay_0.0005-lr_max_0.1-epsilon_0.06274509803921569-num_steps_10-step_size_0.00784313725490196-seed_0-/20220410131028_y63mvmvg/dis_measure_110.pth\"\n",
    "\n",
    "data_ep110 = torch.load(dir_data)\n",
    "\n",
    "mean_all_layer = [value for key, value in data_ep110.items() if \"mean\" in key]\n",
    "var_all_layer = [value for key, value in data_ep110.items() if \"var\" in key]\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(mean_all_layer, label=\"mean\", marker=\".\")\n",
    "# plt.title(\"mean vs layer\")\n",
    "# plt.figure()\n",
    "plt.plot(var_all_layer, label=\"var\", marker=\"^\")\n",
    "# plt.title(\"var vs layer\")\n",
    "plt.ylabel(\"Wasserstein distance\")\n",
    "plt.xlabel(\"Depth of layer\")\n",
    "plt.xticks([i for i in range(len(mean_all_layer))])\n",
    "\n",
    "plt.grid(linestyle='--')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(\"depth_of_layer.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#all_keys = list(all_data[0].keys())\n",
    "import torch\n",
    "from scipy.stats import wasserstein_distance as wd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_path_epoch110='../log_files/BAT-Imagenette-Hybrid_dual_bn/BAT-Imagenette-Hybrid_dual_bn-Madry_mixture_bn--epochs_110-weight_decay_0.0005-lr_max_0.1-epsilon_0.06274509803921569-num_steps_10-step_size_0.00784313725490196-seed_0-/20220410144724_1wuycuyq/modle-epoch110.pt'\n",
    "model_ep110 = torch.load(model_path_epoch110)\n",
    "\n",
    "#print(model_ep110.state_dict().keys())\n",
    "\n",
    "\n",
    "#bn1.bn_list.0.weight   bn1.bn_list.0.bias  bn1.bn_list.0.running_mean   bn1.bn_list.0.running_var\n",
    "#bn1.bn_list.1.weight   bn1.bn_list.1.bias  bn1.bn_list.1.running_mean   bn1.bn_list.1.running_var\n",
    "#bn2.bn_list.0.weight   bn2.bn_list.0.bias  bn2.bn_list.0.running_mean   bn2.bn_list.0.running_var\n",
    "#bn2.bn_list.1.weight   bn2.bn_list.1.bias  bn2.bn_list.1.running_mean   bn2.bn_list.1.running_var\n",
    "# mean_all_bn_layer = [value for key, value in model_ep110.items() if \"bn1.bn_list.0\" in key]\n",
    "# var_all_bn_layer = [value for key, value in model_ep110.items() if \"bn1.bn_list.1\" in key]\n",
    "\n",
    "results={}\n",
    "for k, v in model_ep110.items():\n",
    "    if \"bn_list.0\" in k and \"num_batches_tracked\" not in k:\n",
    "        bn = v\n",
    "        bn_corr = model_ep110[k.replace(\"bn_list.0\", \"bn_list.1\")]\n",
    "        \n",
    "        # print(bn.size())\n",
    "        # print(k)\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "\n",
    "        wd_dis = wd(bn.cpu().numpy(), bn_corr.cpu().numpy())\n",
    "        # print(wd_dis)\n",
    "\n",
    "        results[k] = wd_dis\n",
    "\n",
    "#print(results)\n",
    "    \n",
    "#import ipdb; ipdb.set_trace()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot([v for k, v in results.items() if 'weight' in k], label=\"weight\")\n",
    "plt.plot([v for k, v in results.items() if 'bias' in k], label=\"bias\")\n",
    "plt.plot([v for k, v in results.items() if 'running_mean' in k], label=\"running_mean\" )\n",
    "plt.plot([v for k, v in results.items() if 'running_var' in k], label=\"running_var\")\n",
    "# print(all_keys[30])\n",
    "plt.ylabel(\"Wasserstein distance\")\n",
    "plt.xlabel(\"Depth of layer\")\n",
    "plt.xticks([i for i in range(len([v for k, v in results.items() if 'weight' in k]))])\n",
    "\n",
    "plt.grid(linestyle='--')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"depth_of_layer.png\")\n",
    "\n",
    "\n",
    "# # plt.twinx()\n",
    "# plt.plot([i[all_keys[31]] for i in all_data], label=\"var\", color=\"b\")\n",
    "# print(all_keys[31])\n",
    "\n",
    "\n",
    "# plt.ylabel(\"Wasserstein distance\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "\n",
    "# plt.grid(linestyle='--')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import copy\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from resnet_multi_bn_default_pgd import multi_bn_resnet18\n",
    "\n",
    "\n",
    "# def get_no_current_minibatch_stat_bn(channel):\n",
    "#     return nn.BatchNorm2d(channel, momentum=1)\n",
    "\n",
    "# norm_layer = get_no_current_minibatch_stat_bn\n",
    "\n",
    "# model_for_test = multi_bn_resnet18(norm_layer=norm_layer, bn_names=[\"pgd\", \"normal\"]).cuda()\n",
    "# model_path_epoch110='../log_files/BAT-Imagenette-Hybrid_dual_bn/BAT-Imagenette-Hybrid_dual_bn-Madry_mixture_bn--epochs_110-weight_decay_0.0005-lr_max_0.1-epsilon_0.06274509803921569-num_steps_10-step_size_0.00784313725490196-seed_0-/20220410144724_1wuycuyq/modle-epoch110.pt'\n",
    "\n",
    "# model_state_dict = torch.load(model_path_epoch110)\n",
    "# model_for_test.load_state_dict(model_state_dict)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "trainset = torchvision.datasets.CIFAR10(root='/dev/shm', train=True, download=True, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True,)\n",
    "testset = torchvision.datasets.CIFAR10(root='/dev/shm', train=False, download=True, transform=transform_test)\n",
    "testset.data = testset.data[:1000]\n",
    "testset.targets = testset.targets[:1000]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, )\n",
    "\n",
    "epsilon = 16/255.\n",
    "\n",
    "\n",
    "def generate_adv(model,\n",
    "                x_natural,\n",
    "                y,\n",
    "                optimizer=None,\n",
    "                step_size=0.003,\n",
    "                epsilon=0.031,\n",
    "                perturb_steps=10,\n",
    "                bn_name=\"pgd\",\n",
    "                ):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    adv_images = x_natural.clone().detach()\n",
    "\n",
    "    adv_images = adv_images + torch.empty_like(adv_images).uniform_(-epsilon, epsilon)\n",
    "    adv_images = torch.clamp(adv_images, min=0, max=1).detach()\n",
    "\n",
    "    for _ in range(perturb_steps):\n",
    "        adv_images.requires_grad = True\n",
    "\n",
    "        if bn_name:\n",
    "            outputs = model(adv_images, bn_name)\n",
    "        else:\n",
    "            outputs = model(adv_images)\n",
    "\n",
    "        # Calculate loss\n",
    "        cost = loss(outputs, y)\n",
    "\n",
    "        grad = torch.autograd.grad(cost, adv_images,\n",
    "                                    retain_graph=False, create_graph=False)[0]\n",
    "\n",
    "        adv_images = adv_images.detach() + step_size*grad.sign()\n",
    "        delta = torch.clamp(adv_images - x_natural, min=-epsilon, max=epsilon)\n",
    "        adv_images = torch.clamp(x_natural + delta, min=0, max=1).detach()\n",
    "\n",
    "    return adv_images\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# measure the mismatch between clean and adv\n",
    "def get_no_current_minibatch_stat_bn(channel):\n",
    "    return nn.BatchNorm2d(channel, momentum=1)\n",
    "norm_layer = get_no_current_minibatch_stat_bn\n",
    "bn_names = [\"pgd\", \"normal\"]\n",
    "\n",
    "model_for_measure = multi_bn_resnet18(norm_layer=norm_layer, bn_names=bn_names, num_classes=10).cuda()\n",
    "model_path_epoch110='../log_files/BAT-Imagenette-Hybrid_dual_bn/BAT-Imagenette-Hybrid_dual_bn-Madry_mixture_bn--epochs_110-weight_decay_0.0005-lr_max_0.1-epsilon_0.06274509803921569-num_steps_10-step_size_0.00784313725490196-seed_0-/20220410144724_1wuycuyq/modle-epoch110.pt'\n",
    "\n",
    "model_state_dict = torch.load(model_path_epoch110)\n",
    "\n",
    "model_for_measure.load_state_dict(model_state_dict)\n",
    "# get the stat for clean image\n",
    "print(\"extra feature\")\n",
    "model_for_measure.train()\n",
    "for batch_id, (data, target) in enumerate(test_loader):\n",
    "    data, target = data.cuda(), target.cuda()\n",
    "    data_adv = generate_adv(model_for_measure, data, target, None, step_size=epsilon/4, epsilon=epsilon, perturb_steps=10)\n",
    "    model_for_measure.train()\n",
    "    model_for_measure(data_adv)\n",
    "    adv_stat = copy.deepcopy(model_for_measure.state_dict())\n",
    "    model_for_measure(data)\n",
    "    clean_stat = copy.deepcopy(model_for_measure.state_dict())\n",
    "    break\n",
    "\n",
    "from scipy.stats import wasserstein_distance as wass_dis\n",
    "\n",
    "dis_measure_saver_mean = {}\n",
    "dis_measure_saver_var = {}\n",
    "\n",
    "for (adv_bn_stat_key, adv_bn_stat_value), (clean_bn_stat_key, clean_bn_stat_value) in zip(adv_stat.items(), clean_stat.items()):\n",
    "    if \"bn_list.0.running_mean\" in adv_bn_stat_key:\n",
    "        # import ipdb;ipdb.set_trace()\n",
    "        adv_clean_wass_dis = wass_dis(adv_bn_stat_value.cpu().numpy(), clean_bn_stat_value.cpu().numpy())\n",
    "\n",
    "        dis_measure_saver_mean[adv_bn_stat_key] = adv_clean_wass_dis\n",
    "    if \"bn_list.0.running_var\" in adv_bn_stat_key:\n",
    "        adv_clean_wass_dis = wass_dis(adv_bn_stat_value.cpu().numpy(), clean_bn_stat_value.cpu().numpy())\n",
    "        dis_measure_saver_var[adv_bn_stat_key] = adv_clean_wass_dis\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the trend of affine parameters: layer4.0.bn1.bn_list.0\n",
    "weight_distantce = []\n",
    "bias_distance = []\n",
    "for epoch in range(111):\n",
    "    ckpt_path = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_keys = list(all_data[0].keys())\n",
    "\n",
    "\n",
    "# fig, ax1 = plt.subplots()\n",
    "# ax1.set_ylabel(\"Wasserstein distance (mean)\")\n",
    "# ax1.plot([i[all_keys[30]] for i in all_data], label=\"mean\", color=\"r\")\n",
    "# # plt.legend()\n",
    "# ax2 = ax1.twinx()\n",
    "# ax2.plot([i[all_keys[31]] for i in all_data], label=\"var\", color=\"b\")\n",
    "# ax2.set_ylabel(\"Wasserstein distance (var)\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot([i[all_keys[30]] for i in all_data], label=\"$\\mu$\", color=\"r\")\n",
    "print(all_keys[30])\n",
    "\n",
    "plt.plot([i[all_keys[31]] for i in all_data], label=\"$\\sigma$\", color=\"b\")\n",
    "print(all_keys[31])\n",
    "\n",
    "plt.plot\n",
    "\n",
    "plt.ylabel(\"Wasserstein distance\", fontsize=15)\n",
    "plt.yticks(color=\"r\")\n",
    "plt.xlabel(\"Epoch\", fontsize=15)\n",
    "plt.xticks( fontsize=12)\n",
    "plt.yticks( fontsize=12)\n",
    "\n",
    "# plt.twinx()\n",
    "# plt.plot([i[all_keys[31]] for i in all_data], label=\"var\", color=\"b\")\n",
    "# print(all_keys[31])\n",
    "# plt.yticks( fontsize=12)\n",
    "\n",
    "\n",
    "# plt.ylabel(\"Wasserstein distance (var $\\mu$)\", color=\"b\", fontsize=15)\n",
    "# plt.yticks(color=\"b\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "\n",
    "plt.grid(linestyle='--')\n",
    "# plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"zcs_layer4_firstbn_meanvar.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_keys = list(all_data[0].keys())\n",
    "\n",
    "\n",
    "# fig, ax1 = plt.subplots()\n",
    "# ax1.set_ylabel(\"Wasserstein distance (mean)\")\n",
    "# ax1.plot([i[all_keys[30]] for i in all_data], label=\"mean\", color=\"r\")\n",
    "# # plt.legend()\n",
    "# ax2 = ax1.twinx()\n",
    "# ax2.plot([i[all_keys[31]] for i in all_data], label=\"var\", color=\"b\")\n",
    "# ax2.set_ylabel(\"Wasserstein distance (var)\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot([i[all_keys[30]] for i in all_data], label=\"mean\", color=\"r\")\n",
    "print(all_keys[30])\n",
    "\n",
    "plt.ylabel(\"Wasserstein distance (mean $\\mu$)\", color=\"r\", fontsize=15)\n",
    "plt.yticks(color=\"r\")\n",
    "plt.xlabel(\"Epoch\", fontsize=15)\n",
    "plt.xticks( fontsize=12)\n",
    "plt.yticks( fontsize=12)\n",
    "\n",
    "plt.twinx()\n",
    "plt.plot([i[all_keys[31]] for i in all_data], label=\"var\", color=\"b\")\n",
    "print(all_keys[31])\n",
    "plt.yticks( fontsize=12)\n",
    "\n",
    "\n",
    "plt.ylabel(\"Wasserstein distance (var $\\mu$)\", color=\"b\", fontsize=15)\n",
    "plt.yticks(color=\"b\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "\n",
    "plt.grid(linestyle='--')\n",
    "# plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"zcs_layer4_firstbn_meanvar.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# all_keys = list(all_data[0].keys())\n",
    "\n",
    "# for layer, key in enumerate(all_keys):\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.plot([i[key] for i in all_data], label=\"1st BN\")\n",
    "#     plt.title(key + str(layer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "7c98ccfd83d7b36b2dafdad6fe27613e9cbde0f2c8afbb6d4524b864a80622b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
